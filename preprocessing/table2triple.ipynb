{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin sampling ...\n",
      "Processing DEMOGRAPHIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-86d51f45aa4d>:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_demo_sample[k] = data_demo_sample[k].apply(lambda x: x.lower() if type(x) == str else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32725\n",
      "Processing PRESCRIPTIONS\n",
      "Done!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import shutil\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.evaluation.process_mimic_db.utils import *\n",
    "from utils.evaluation.process_mimic_db.process_tables import *\n",
    "\n",
    "# Specify the path to the downloaded MIMIC III data\n",
    "data_dir = 'mimic_table'\n",
    "# Path to the generated mimic.db. No need to update.\n",
    "out_dir = 'mimic_db'\n",
    "db = 'px'\n",
    "\n",
    "# Generate five tables and the database with all admissions\n",
    "# if os.path.exists(out_dir):\n",
    "#     shutil.rmtree(out_dir)\n",
    "# os.mkdir(out_dir)\n",
    "'''\n",
    "conn = sqlite3.connect(os.path.join(out_dir, 'mimic_all.db'))\n",
    "build_demographic_table(data_dir, out_dir, conn)\n",
    "build_diagnoses_table(data_dir, out_dir, conn)\n",
    "build_procedures_table(data_dir, out_dir, conn)\n",
    "build_prescriptions_table(data_dir, out_dir, conn)\n",
    "build_lab_table(data_dir, out_dir, conn)\n",
    "'''\n",
    "\n",
    "'''\n",
    "1. We did not emumerate all possible questions about MIMIC III.\n",
    "MIMICSQL data is generated based on the patient information \n",
    "related to 100 randomly selected admissions.\n",
    "2. The following codes are used for sampling the admissions \n",
    "from the large database. \n",
    "3. The parameter 'random_state=0' in line 41 will provide you \n",
    "the same set of sampled admissions and the same database as we used.\n",
    "'''\n",
    "\n",
    "print('Begin sampling ...')\n",
    "# DEMOGRAPHIC\n",
    "print('Processing DEMOGRAPHIC')\n",
    "conn = sqlite3.connect(os.path.join(out_dir, 'mimic.db'))\n",
    "data_demo = pandas.read_csv(os.path.join(out_dir, \"DEMOGRAPHIC.csv\"))\n",
    "h_adm_list = [elem[0] for elem in torch.load(f'result-{db}/p_sections')]\n",
    "data_demo_sample = data_demo[data_demo['HADM_ID'].isin(h_adm_list)]\n",
    "for k, v in data_demo_sample.dtypes.items():\n",
    "    data_demo_sample[k] = data_demo_sample[k].apply(lambda x: x.lower() if type(x) == str else x)\n",
    "print(f'# admissions : {len(data_demo_sample)}')\n",
    "#data_demo_sample.to_sql('DEMOGRAPHIC', conn, if_exists='replace', index=False)\n",
    "sampled_id = data_demo_sample['HADM_ID'].values\n",
    "\n",
    "if 'dx' in db:\n",
    "    # DIAGNOSES\n",
    "    print('Processing DIAGNOSES')\n",
    "    data_input = pandas.read_csv(os.path.join(out_dir, \"DIAGNOSES.csv\"))\n",
    "    data_filter = []\n",
    "    cnt = 0\n",
    "    for itm in sampled_id:\n",
    "        msg = 'HADM_ID=='+str(itm)\n",
    "        data_filter.append(data_input.query(msg))\n",
    "        cnt += 1\n",
    "        show_progress(cnt, len(sampled_id))\n",
    "    data_out = pandas.concat(data_filter, ignore_index=True)\n",
    "    for k, v in data_out.dtypes.items():\n",
    "        data_out[k] = data_out[k].apply(lambda x: x.lower() if type(x) == str else x)\n",
    "    data_out.to_sql('DIAGNOSES', conn, if_exists='replace', index=False)\n",
    "\n",
    "if 'prx' in db:\n",
    "    # PROCEDURES\n",
    "    print('Processing PROCEDURES')\n",
    "    data_input = pandas.read_csv(os.path.join(out_dir, \"PROCEDURES.csv\"))\n",
    "    data_filter = []\n",
    "    cnt = 0\n",
    "    for itm in sampled_id:\n",
    "        msg = 'HADM_ID=='+str(itm)\n",
    "        data_filter.append(data_input.query(msg))\n",
    "        cnt += 1\n",
    "        show_progress(cnt, len(sampled_id))\n",
    "    data_out = pandas.concat(data_filter, ignore_index=True)\n",
    "    for k, v in data_out.dtypes.items():\n",
    "        data_out[k] = data_out[k].apply(lambda x: x.lower() if type(x) == str else x)\n",
    "    data_out.to_sql('PROCEDURES', conn, if_exists='replace', index=False)\n",
    "\n",
    "if 'px' in db:\n",
    "    # PRESCRIPTIONS\n",
    "    print('Processing PRESCRIPTIONS')\n",
    "    data_input = pandas.read_csv(os.path.join(out_dir, \"PRESCRIPTIONS.csv\"))\n",
    "    data_filter = []\n",
    "    cnt = 0\n",
    "    for itm in sampled_id:\n",
    "        msg = 'HADM_ID=='+str(itm)\n",
    "        data_filter.append(data_input.query(msg))\n",
    "        cnt += 1\n",
    "        show_progress(cnt, len(sampled_id))\n",
    "    data_out = pandas.concat(data_filter, ignore_index=True)\n",
    "    for k, v in data_out.dtypes.items():\n",
    "        data_out[k] = data_out[k].apply(lambda x: x.lower() if type(x) == str else x)\n",
    "    data_out.to_sql('PRESCRIPTIONS', conn, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "if 'lab' in db:\n",
    "    # LAB\n",
    "    print('Processing LAB')\n",
    "    data_input = pandas.read_csv(os.path.join(out_dir, \"LAB.csv\"))\n",
    "    data_filter = []\n",
    "    cnt = 0\n",
    "    for itm in sampled_id:\n",
    "        msg = 'HADM_ID=='+str(itm)\n",
    "        data_filter.append(data_input.query(msg))\n",
    "        cnt += 1\n",
    "        show_progress(cnt, len(sampled_id))\n",
    "    data_out = pandas.concat(data_filter, ignore_index=True)\n",
    "    for k, v in data_out.dtypes.items():\n",
    "        data_out[k] = data_out[k].apply(lambda x: x.lower() if type(x) == str else x)\n",
    "    data_out.to_sql('LAB', conn, if_exists='replace', index=False)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PJT_ROOT_PATH:  ./\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2859767 entries, 0 to 2859766\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   SUBJECT_ID         int64  \n",
      " 1   PRESCRIPTIONS      int64  \n",
      " 2   HADM_ID            int64  \n",
      " 3   ICUSTAY_ID         float64\n",
      " 4   DRUG_TYPE          object \n",
      " 5   DRUG               object \n",
      " 6   FORMULARY_DRUG_CD  object \n",
      " 7   ROUTE              object \n",
      " 8   DRUG_DOSE          object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 196.4+ MB\n",
      "LOAD DB ...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('.')\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from utils.schema_mimic import *\n",
    "from utils.evaluation.utils import query\n",
    "\n",
    "PJT_ROOT_PATH = './'\n",
    "print('PJT_ROOT_PATH: ',PJT_ROOT_PATH)\n",
    "\n",
    "db_conn = sqlite3.connect(os.path.join(PJT_ROOT_PATH, 'mimic_db/mimic.db'))\n",
    "conn = sqlite3.connect(os.path.join(PJT_ROOT_PATH , 'mimicsqlstar.db')) \n",
    "'''\n",
    "patient_cols = list(patient_demographic_dtype.keys())\n",
    "addmission_cols = list(hadm_demographic_dtype.keys())\n",
    "\n",
    "demographic = pd.read_sql_query(\"SELECT * FROM DEMOGRAPHIC\", db_conn)\n",
    "demographic.info()\n",
    "demographic.head()\n",
    "\n",
    "patients_df = demographic.loc[:,patient_cols]\n",
    "patients_df.info()\n",
    "\n",
    "addmissions_df = demographic.loc[:,addmission_cols] # primary key: HADM_ID\n",
    "addmissions_df.info()\n",
    "'''\n",
    "if 'dx' in db:\n",
    "    diagenoses = pd.read_sql_query(\"SELECT * FROM DIAGNOSES\", db_conn)\n",
    "    diagenoses = diagenoses.reset_index().rename({'index': 'DIAGNOSES'}, axis=1)\n",
    "    diagenoses.info()\n",
    "\n",
    "    diagnoses_cols = list(diagnoses_dtype.keys())\n",
    "    d_icd_dagnoses_cols = list(d_icd_diagnoses_dtype.keys())\n",
    "    diagnoses_cols = ['ICD9_CODE' if c == 'DIAGNOSES_ICD9_CODE' else c for c in diagnoses_cols]\n",
    "    d_icd_dagnoses_cols = ['ICD9_CODE' if c == 'DIAGNOSES_ICD9_CODE' else c for c in d_icd_dagnoses_cols]\n",
    "    d_icd_dagnoses_cols = ['LONG_TITLE' if c == 'DIAGNOSES_LONG_TITLE' else c for c in d_icd_dagnoses_cols]\n",
    "    #d_icd_dagnoses_cols = ['SHORT_TITLE' if c == 'DIAGNOSES_SHORT_TITLE' else c for c in d_icd_dagnoses_cols]\n",
    "\n",
    "    diagenoses_df = diagenoses.loc[:, diagnoses_cols]\n",
    "    diagenoses_df.info()\n",
    "\n",
    "    d_icd_diagenoses_df = diagenoses.loc[:, d_icd_dagnoses_cols]\n",
    "    d_icd_diagenoses_df.drop_duplicates(inplace=True)\n",
    "    d_icd_diagenoses_df.reset_index(inplace=True, drop=True)\n",
    "    d_icd_diagenoses_df.info()\n",
    "    \n",
    "    diagenoses_df.to_sql('DIAGNOSES', conn, if_exists='replace', index=False)\n",
    "    d_icd_diagenoses_df.to_sql('D_ICD_DIAGNOSES', conn, if_exists='replace', index=False)\n",
    "    \n",
    "if 'prx' in db:\n",
    "    procedures = pd.read_sql_query(\"SELECT * FROM PROCEDURES\", db_conn)\n",
    "    procedures = procedures.reset_index().rename({'index': 'PROCEDURES'}, axis=1)\n",
    "    procedures.info()\n",
    "\n",
    "    procedures_cols = list(procedures_dtype.keys())\n",
    "    d_icd_procedures_cols = list(d_icd_procedures_dtype.keys())\n",
    "    procedures_cols = ['ICD9_CODE' if c == 'PROCEDURES_ICD9_CODE' else c for c in procedures_cols]\n",
    "    d_icd_procedures_cols = ['ICD9_CODE' if c == 'PROCEDURES_ICD9_CODE' else c for c in d_icd_procedures_cols]\n",
    "    d_icd_procedures_cols = ['LONG_TITLE' if c == 'PROCEDURES_LONG_TITLE' else c for c in d_icd_procedures_cols]\n",
    "    #d_icd_procedures_cols = ['SHORT_TITLE' if c == 'PROCEDURES_SHORT_TITLE' else c for c in d_icd_procedures_cols]\n",
    "\n",
    "    procedures_df = procedures.loc[:, procedures_cols]\n",
    "    procedures_df.info()\n",
    "\n",
    "    d_icd_procedures_df = procedures.loc[:, d_icd_procedures_cols]\n",
    "    d_icd_procedures_df.drop_duplicates(inplace=True)\n",
    "    d_icd_procedures_df.reset_index(inplace=True, drop=True)\n",
    "    d_icd_procedures_df.info()\n",
    "    \n",
    "    procedures_df.to_sql('PROCEDURES', conn, if_exists='replace', index=False)\n",
    "    d_icd_procedures_df.to_sql('D_ICD_PROCEDURES', conn, if_exists='replace', index=False)\n",
    "    \n",
    "if 'lab' in db:\n",
    "    lab_cols = list(lab_dtype.keys())\n",
    "    d_labitem_cols = list(d_labitem_dtype.keys())\n",
    "\n",
    "    lab = pd.read_sql_query(\"SELECT * FROM LAB\", db_conn)\n",
    "    lab = lab.reset_index().rename({'index': 'LAB'}, axis=1)\n",
    "    lab.info()\n",
    "\n",
    "    lab_df = lab.loc[:, lab_cols]\n",
    "    lab_df.info()\n",
    "\n",
    "    d_labitem_df = lab.loc[:, d_labitem_dtype]\n",
    "    d_labitem_df.drop_duplicates(inplace=True)\n",
    "    d_labitem_df.reset_index(inplace=True, drop=True)\n",
    "    d_labitem_df.info()\n",
    "    \n",
    "    lab_df.to_sql('LAB', conn, if_exists='replace', index=False)\n",
    "    d_labitem_df.to_sql('D_LABITEM', conn, if_exists='replace', index=False)\n",
    "    \n",
    "if 'px' in db:\n",
    "    prescriptions_cols = list(prescriptions_dtype.keys())\n",
    "\n",
    "    prescriptions = pd.read_sql_query(\"SELECT * FROM PRESCRIPTIONS\", db_conn)\n",
    "    prescriptions = prescriptions.reset_index().rename({'index': 'PRESCRIPTIONS'}, axis=1)\n",
    "    prescriptions_df = prescriptions.loc[:, prescriptions_cols]\n",
    "    prescriptions_df.info()\n",
    "    \n",
    "    prescriptions_df.to_sql('PRESCRIPTIONS', conn, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "'''\n",
    "patients_df.to_sql('PATIENTS', conn, if_exists='replace', index=False)\n",
    "addmissions_df.to_sql('ADMISSIONS', conn, if_exists='replace', index=False)\n",
    "'''\n",
    "print(f'LOAD DB ...')\n",
    "\n",
    "db_file = os.path.join(PJT_ROOT_PATH,'mimicsqlstar.db')\n",
    "new_model = query(db_file)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PJT_ROOT_PATH:  ./\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2859767 entries, 0 to 2859766\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   SUBJECT_ID         int64 \n",
      " 1   PRESCRIPTIONS      int64 \n",
      " 2   HADM_ID            int64 \n",
      " 3   ICUSTAY_ID         object\n",
      " 4   DRUG_TYPE          object\n",
      " 5   DRUG               object\n",
      " 6   FORMULARY_DRUG_CD  object\n",
      " 7   ROUTE              object\n",
      " 8   DRUG_DOSE          object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 196.4+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [12:46<00:00, 95.81s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total triples : 18978885\n",
      "SAVE KG ...\n",
      "SAVE DONE\n",
      "LOAD TEST ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-1b193f68796f>\", line 178, in <module>\n",
      "    kg.parse('./mimic_sparqlstar_kg.xml', format='xml', publicID='/')\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/rdflib/graph.py\", line 1078, in parse\n",
      "    parser.parse(source, self, **args)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/rdflib/plugins/parsers/rdfxml.py\", line 579, in parse\n",
      "    self._parser.parse(source)\n",
      "  File \"/root/miniconda3/lib/python3.8/xml/sax/expatreader.py\", line 111, in parse\n",
      "    xmlreader.IncrementalParser.parse(self, source)\n",
      "  File \"/root/miniconda3/lib/python3.8/xml/sax/xmlreader.py\", line 125, in parse\n",
      "    self.feed(buffer)\n",
      "  File \"/root/miniconda3/lib/python3.8/xml/sax/expatreader.py\", line 217, in feed\n",
      "    self._parser.Parse(data, isFinal)\n",
      "  File \"/tmp/build/80754af9/python_1599203911753/work/Modules/pyexpat.c\", line 407, in StartElement\n",
      "  File \"/root/miniconda3/lib/python3.8/xml/sax/expatreader.py\", line 369, in start_element_ns\n",
      "    self._cont_handler.startElementNS(pair, None,\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/rdflib/plugins/parsers/rdfxml.py\", line 158, in startElementNS\n",
      "    current.start(name, qname, attrs)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/rdflib/plugins/parsers/rdfxml.py\", line 338, in property_element_start\n",
      "    name, atts = self.convert(name, qname, attrs)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/rdflib/plugins/parsers/rdfxml.py\", line 230, in convert\n",
      "    atts[URIRef(att)] = v\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/rdflib/term.py\", line 230, in __new__\n",
      "    if not _is_valid_uri(value):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/rdflib/term.py\", line 79, in _is_valid_uri\n",
      "    return all(map(lambda c: ord(c) > 256 or not c in _invalid_uri_chars, uri))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/root/miniconda3/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/root/miniconda3/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/root/miniconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/root/miniconda3/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/root/miniconda3/lib/python3.8/inspect.py\", line 721, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/root/miniconda3/lib/python3.8/posixpath.py\", line 381, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/root/miniconda3/lib/python3.8/posixpath.py\", line 362, in normpath\n",
      "    new_comps.append(comp)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1b193f68796f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0mkg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m \u001b[0mkg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mimic_sparqlstar_kg.xml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'xml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublicID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, publicID, format, location, file, data, **args)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/rdflib/plugins/parsers/rdfxml.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, sink, **args)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m# self._parser.reset()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/xml/sax/expatreader.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cont_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetDocumentLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExpatLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mxmlreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/xml/sax/xmlreader.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/xml/sax/expatreader.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data, isFinal)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;31m# except when invoked from close.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misFinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/build/80754af9/python_1599203911753/work/Modules/pyexpat.c\u001b[0m in \u001b[0;36mStartElement\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/xml/sax/expatreader.py\u001b[0m in \u001b[0;36mstart_element_ns\u001b[0;34m(self, name, attrs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         self._cont_handler.startElementNS(pair, None,\n\u001b[0m\u001b[1;32m    370\u001b[0m                                           AttributesNSImpl(newattrs, qnames))\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/rdflib/plugins/parsers/rdfxml.py\u001b[0m in \u001b[0;36mstartElementNS\u001b[0;34m(self, name, qname, attrs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/rdflib/plugins/parsers/rdfxml.py\u001b[0m in \u001b[0;36mproperty_element_start\u001b[0;34m(self, name, qname, attrs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproperty_element_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/rdflib/plugins/parsers/rdfxml.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, name, qname, attrs)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0matts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mURIRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/rdflib/term.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, value, base)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s does not look like a valid URI, trying to serialize this will break.'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/rdflib/term.py\u001b[0m in \u001b[0;36m_is_valid_uri\u001b[0;34m(uri)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_valid_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m256\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_invalid_uri_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "sys.path.append('..')\n",
    "sys.path.append('.')\n",
    "from rdflib import Graph, URIRef\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from rdflib import Literal\n",
    "from tqdm import tqdm\n",
    "from utils.kg_complex_schema import addmissions_dtype, patients_dtype, procedures_dtype, prescriptions_dtype,\\\n",
    "    diagnoses_dtype, lab_dtype, d_icd_procedures_dtype, d_icd_diagnoses_dtype, d_labitem_dtype\n",
    "\n",
    "PJT_ROOT_PATH = './'\n",
    "print('PJT_ROOT_PATH: ', PJT_ROOT_PATH)\n",
    "\n",
    "domain = ''\n",
    "\n",
    "def isNoneNan(val):\n",
    "    if val is None:\n",
    "        return True\n",
    "\n",
    "    if (type(val) == str) and (val.lower() in ['none', 'nan']):\n",
    "        return True\n",
    "\n",
    "    if val != val:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def clean_text(val):\n",
    "    if type(val) == str:\n",
    "        val = val.replace(\"\\\\\", ' ')\n",
    "    return val\n",
    "\n",
    "\n",
    "def wrap2uri(obj, literal_type):\n",
    "    obj = obj.lower()\n",
    "    if literal_type == 'entity':\n",
    "        return URIRef(obj)\n",
    "\n",
    "    elif literal_type == 'relation':\n",
    "        return URIRef(obj)\n",
    "\n",
    "    else:\n",
    "        return Literal(clean_text(obj), datatype=literal_type)\n",
    "\n",
    "\n",
    "def table2triples(knowgraph,df, parent_col, subject_col, col_types):\n",
    "    #triples = []\n",
    "    for col_name, _ in tqdm(col_types.items()):\n",
    "\n",
    "        if col_name == parent_col:\n",
    "            # triples += [(wrap2uri(f'{domain}/{col_name}/{sub}', col_types[parent_col]),\n",
    "            #              wrap2uri(f'{domain}/{subject_col}', 'relation'),\n",
    "            #              wrap2uri(f'{domain}/{subject_col}/{obj}', col_types[subject_col]))\n",
    "            #             for (sub, obj) in zip(df[col_name], df[subject_col])]\n",
    "            for (sub, obj) in zip(df[col_name], df[subject_col]):\n",
    "                knowgraph.add((wrap2uri(f'{domain}/{col_name}/{sub}', col_types[parent_col]),\n",
    "                             wrap2uri(f'{domain}/{subject_col}', 'relation'),\n",
    "                             wrap2uri(f'{domain}/{subject_col}/{obj}', col_types[subject_col]))\n",
    "                            )\n",
    "            continue\n",
    "\n",
    "        if col_name == subject_col:\n",
    "            continue\n",
    "        for (sub, obj) in zip(df[subject_col], df[col_name]):\n",
    "            if not isNoneNan(obj):\n",
    "                knowgraph.add(\n",
    "                            (wrap2uri(f'{domain}/{subject_col}/{sub}', col_types[subject_col]),\n",
    "                             wrap2uri(f'{domain}/{col_name}', 'relation'),\n",
    "                             wrap2uri(f'{domain}/{col_name}/{obj}' if col_types[col_name] == 'entity' else f'{obj}',\n",
    "                                      col_types[col_name]))\n",
    "                             )\n",
    "\n",
    "    return knowgraph\n",
    "\n",
    "db_conn = sqlite3.connect(os.path.join(PJT_ROOT_PATH, 'mimicsqlstar.db'))\n",
    "kg = Graph()\n",
    "'''\n",
    "patients = pd.read_sql_query(\"SELECT * FROM PATIENTS\", db_conn)\n",
    "patients.info()\n",
    "\n",
    "admissions = pd.read_sql_query(\"SELECT * FROM ADMISSIONS\", db_conn)\n",
    "admissions.info()\n",
    "'''\n",
    "if 'dx' in db:\n",
    "    diagnoses = pd.read_sql_query(\"SELECT * FROM DIAGNOSES\", db_conn)\n",
    "    diagnoses = diagnoses.rename({'ICD9_CODE': 'DIAGNOSES_ICD9_CODE'}, axis=1)\n",
    "    diagnoses.info()\n",
    "\n",
    "    d_icd_diagnoses = pd.read_sql_query(\"SELECT * FROM D_ICD_DIAGNOSES\", db_conn)\n",
    "    d_icd_diagnoses = d_icd_diagnoses.rename({'ICD9_CODE': 'DIAGNOSES_ICD9_CODE',\n",
    "                                              #'SHORT_TITLE': 'DIAGNOSES_SHORT_TITLE',\n",
    "                                              'LONG_TITLE': 'DIAGNOSES_LONG_TITLE'}, axis=1)\n",
    "    d_icd_diagnoses.info()\n",
    "    kg = table2triples(kg,diagnoses, parent_col='HADM_ID', subject_col='DIAGNOSES', col_types=diagnoses_dtype)\n",
    "    print('# total triples : {}'.format(len(kg)))\n",
    "    kg = table2triples(kg,d_icd_diagnoses, parent_col='', subject_col='DIAGNOSES_ICD9_CODE',\n",
    "                         col_types=d_icd_diagnoses_dtype)\n",
    "    print('# total triples : {}'.format(len(kg)))\n",
    "    \n",
    "if 'prx' in db:\n",
    "    procedures = pd.read_sql_query(\"SELECT * FROM PROCEDURES\", db_conn)\n",
    "    procedures = procedures.rename({'ICD9_CODE': 'PROCEDURES_ICD9_CODE'}, axis=1)\n",
    "    procedures.info()\n",
    "\n",
    "    d_icd_procedures = pd.read_sql_query(\"SELECT * FROM D_ICD_PROCEDURES\", db_conn)\n",
    "    d_icd_procedures = d_icd_procedures.rename({'ICD9_CODE': 'PROCEDURES_ICD9_CODE',\n",
    "                                                #'SHORT_TITLE': 'PROCEDURES_SHORT_TITLE',\n",
    "                                                'LONG_TITLE': 'PROCEDURES_LONG_TITLE'}, axis=1)\n",
    "    d_icd_procedures.info()\n",
    "    kg = table2triples(kg,procedures, parent_col='HADM_ID', subject_col='PROCEDURES', col_types=procedures_dtype)\n",
    "    print('# total triples : {}'.format(len(kg)))\n",
    "\n",
    "    kg = table2triples(kg,d_icd_procedures, parent_col='', subject_col='PROCEDURES_ICD9_CODE',\n",
    "                             col_types=d_icd_procedures_dtype)\n",
    "    print('# total triples : {}'.format(len(kg)))\n",
    "    \n",
    "if 'px' in db:\n",
    "    prescriptions = pd.read_sql_query(\"SELECT * FROM PRESCRIPTIONS\", db_conn)\n",
    "    prescriptions['ICUSTAY_ID'] = prescriptions['ICUSTAY_ID'].apply(lambda x: str(x) if x == x else None)\n",
    "    prescriptions.info()\n",
    "    \n",
    "    kg = table2triples(kg,prescriptions, parent_col='HADM_ID', subject_col='PRESCRIPTIONS',\n",
    "                         col_types=prescriptions_dtype)\n",
    "    print('# total triples : {}'.format(len(kg)))\n",
    "\n",
    "\n",
    "if 'lab' in db:\n",
    "    lab = pd.read_sql_query(\"SELECT * FROM LAB\", db_conn)\n",
    "    lab.info()\n",
    "\n",
    "    d_labitem = pd.read_sql_query(\"SELECT * FROM D_LABITEM\", db_conn)\n",
    "    d_labitem.info()\n",
    "    \n",
    "    kg = table2triples(kg,lab, parent_col='HADM_ID', subject_col='LAB', col_types=lab_dtype)\n",
    "    print('# total triples : {}'.format(len(kg)))\n",
    "    kg = table2triples(kg,d_labitem, parent_col='', subject_col='ITEMID', col_types=d_labitem_dtype)\n",
    "    print('# total triples : {}'.format(len(kg)))\n",
    "    \n",
    "\n",
    "'''\n",
    "kg = table2triples(kg,patients, parent_col='', subject_col='SUBJECT_ID', col_types=patients_dtype)\n",
    "print('# total triples : {}'.format(len(kg)))\n",
    "# print(triples[:5])\n",
    "#print(triples[-5:])\n",
    "#print(len(triples))\n",
    "\n",
    "kg = table2triples(kg,admissions, parent_col='SUBJECT_ID', subject_col='HADM_ID',\n",
    "                         col_types=addmissions_dtype)\n",
    "print('# total triples : {}'.format(len(kg)))\n",
    "# print(triples[-5:])\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "q = \"\"\"select * where { ?subject_id </gender> \"f\"^^<http://www.w3.org/2001/XMLSchema#string> }\"\"\"\n",
    "print(f\"TEST QEURY... {q})\")\n",
    "qres = kg.query(q)\n",
    "print(\"-\" * 50)\n",
    "for res in qres:\n",
    "    val = '|'\n",
    "    for t in res:\n",
    "        val += str(t.toPython()) + '|\\t\\t|'\n",
    "    print(val[:-1])\n",
    "print()\n",
    "'''\n",
    "\n",
    "\n",
    "print('SAVE KG ...')\n",
    "kg.serialize('./mimic_sparqlstar_kg.xml', format='xml')\n",
    "print('SAVE DONE')\n",
    "\n",
    "print('LOAD TEST ...')\n",
    "kg = Graph()\n",
    "kg.parse('./mimic_sparqlstar_kg.xml', format='xml', publicID='/')\n",
    "\n",
    "print(len(kg))\n",
    "for i, t in enumerate(kg):\n",
    "    print(i, t)\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "print('LOAD DONE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11246613/11246613 [03:01<00:00, 61871.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2929988\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "def build_dict(triples, nodes, edges):\n",
    "    h, r, t = triples\n",
    "    #for (h,r,t) in triples:\n",
    "    if h not in nodes:\n",
    "        nodes[h]=1\n",
    "    else:\n",
    "        nodes[h]+=1\n",
    "    if t not in nodes:\n",
    "        nodes[t]=1\n",
    "    else:\n",
    "        nodes[t]+=1\n",
    "    if r not in edges:\n",
    "        edges[r]=1\n",
    "    else:\n",
    "        edges[r]+=1\n",
    "    return nodes, edges\n",
    "\n",
    "# triple 확인\n",
    "nodes = dict()\n",
    "edges = dict()\n",
    "for triple in tqdm(kg):\n",
    "    triples = [x.n3() for x in triple]\n",
    "    #print(triples)\n",
    "    nodes, edges = build_dict(triples, nodes, edges)\n",
    "#matching = [s for s in tqdm(list(nodes.keys())) if \"hadm_id\" in list(nodes.keys())]\n",
    "print(len(nodes))\n",
    "print(len(edges))\n",
    "\n",
    "f = open('node_dict','w')\n",
    "g = open('edge_dict','w')\n",
    "for node in list(nodes.keys()):\n",
    "    f.write('{}\\n'.format(node))\n",
    "for edge in list(edges.keys()):\n",
    "    g.write('{}\\n'.format(edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11246613/11246613 [03:01<00:00, 61905.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make file & Build look-up table\n",
    "train2id = open('train2id.txt','w')\n",
    "train2id.write(str(len(kg))+'\\n')\n",
    "node2id = open('entity2id.txt','w')\n",
    "node_lookup = {k:v for (v,k) in enumerate(nodes)}\n",
    "node2id.write(str(len(nodes))+'\\n')\n",
    "edge2id = open('relation2id.txt','w')\n",
    "edge_lookup = {k:v for (v,k) in enumerate(edges)}\n",
    "edge2id.write(str(len(edges))+'\\n')\n",
    "\n",
    "# Build Node lookup\n",
    "for (node, idx) in list(node_lookup.items()):\n",
    "    node2id.write('{}\\t{}\\n'.format(node, idx))\n",
    "\n",
    "# Build Edge lookup\n",
    "for (edge, idx) in list(edge_lookup.items()):\n",
    "    edge2id.write('{}\\t{}\\n'.format(edge, idx))\n",
    "\n",
    "# Actual triple to id triple\n",
    "for triple in tqdm(kg):\n",
    "    triples = [x.n3() for x in triple]\n",
    "    train2id.write('{}\\t{}\\t{}\\n'.format(node_lookup[triples[0]],node_lookup[triples[2]],edge_lookup[triples[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
