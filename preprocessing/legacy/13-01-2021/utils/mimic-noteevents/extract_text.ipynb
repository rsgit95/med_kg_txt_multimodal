{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/exp/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3418: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NOTEEVENTS successfully!\n",
      "Get discharge summary successfully!\n",
      "Preprocess notes successfully!\n",
      "save successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json \n",
    "import argparse\n",
    "import os\n",
    "\n",
    "ROOT_PATH = 'result'\n",
    "if not os.path.isdir(ROOT_PATH):\n",
    "    os.mkdir(ROOT_PATH)\n",
    "\n",
    "LOAD_FILE_PATH = 'mimic_table/NOTEEVENTS.csv'\n",
    "SAVE_FILE_PATH = 'sections.csv'\n",
    "\n",
    "\n",
    "'''\n",
    "Table --> Sections\n",
    "\n",
    "1. load NOTEEVENTS.csv\n",
    "\n",
    "2. get discharge sumamry notes\n",
    "    a) NOTEVENTS.CATEGORY = 'Discharge Summary'\n",
    "    b) NOTEVENTS.DESCRIPTION = 'Report'\n",
    "    c) eliminate a short-note\n",
    "\n",
    "3. preprocess discharge sumamry notes\n",
    "    a) clean text\n",
    "    b) split sections by headers\n",
    "    \n",
    "4. save csv file\n",
    "    a) PK: NOTEVENTS.ROW_ID\n",
    "    b) TEXT: string(doubled-list)\n",
    "    \n",
    "'''\n",
    "\n",
    "def load_noteevents(file_path):\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # dataframe dtype config\n",
    "    df.CHARTDATE = pd.to_datetime(df.CHARTDATE, format='%Y-%m-%d', errors='raise')\n",
    "    df.CHARTTIME = pd.to_datetime(df.CHARTTIME, format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "    df.STORETIME = pd.to_datetime(df.STORETIME)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_csv_file(csv_data, file_path):\n",
    "    csv_data.to_csv(file_path, index=False)\n",
    "    print('save successfully!')\n",
    "\n",
    "\n",
    "def get_discharge_summary(df_notevents):\n",
    "\n",
    "    cond1 = (df_notevents.CATEGORY == 'Discharge summary')\n",
    "    cond2 = (df_notevents.DESCRIPTION == 'Report')\n",
    "\n",
    "    df_discharge_smmary = df_notevents[cond1&cond2]\n",
    "    df_discharge_smmary = df_discharge_smmary[['ROW_ID', 'TEXT']]\n",
    "    \n",
    "    # eliminate a short-note (subject_id=30561, hadm_id=178941)\n",
    "    df_discharge_smmary = df_discharge_smmary[df_discharge_smmary.TEXT.apply(lambda x: len(x) > 100)]\n",
    "\n",
    "    return df_discharge_smmary\n",
    "\n",
    "\n",
    "def pattern_repl(matchobj):\n",
    "    # Return a replacement string to be used for match object\n",
    "    return ' '.rjust(len(matchobj.group(0)))  \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Replace [**Patterns**] with spaces.\n",
    "    text = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', pattern_repl, text)\n",
    "    \n",
    "    # 2. Replace `_` with spaces.\n",
    "    new_text = re.sub(r'_', ' ', text)\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "\n",
    "def split_section(text):\n",
    "    headers, sections = [], []\n",
    "#     pattern = \"^([A-z0-9 ]+)(:)|Discharge Date:|Sex:|JOB#:|Unit No:|FOLLOW-UP PLANS:\"\n",
    "    except_pattern = \"(?!(Sig:)|(disp:))\"\n",
    "    include_keywords = \"(Discharge Date:)|(Sex:)|(JOB#:)|(Unit No:)|(FOLLOW-UP PLANS:)\"\n",
    "    pattern = \"^\" + except_pattern + \"([A-z0-9 ]+)(:)|\" + include_keywords\n",
    "    SEPERATORS = re.compile(pattern, re.I | re.M)\n",
    "    start = 0\n",
    "    \n",
    "    for matcher in SEPERATORS.finditer(text):\n",
    "        # cut off by the position of later SEPERATOR\n",
    "        end = matcher.start()\n",
    "        if end != start: # except for first line\n",
    "            section = text[start:end]\n",
    "            if ':' not in section: #\n",
    "                pass\n",
    "            else:\n",
    "                section = section[len(header):].strip() # except for header in section\n",
    "                sections.append(section)\n",
    "        start = end\n",
    "        end = matcher.end()\n",
    "        \n",
    "        # collect each title in the beginning of section\n",
    "        header = text[start:end].lower()\n",
    "        headers.append(header)\n",
    "        \n",
    "    # add last section\n",
    "    section = text[start:]\n",
    "    section = section[len(header):].strip()\n",
    "    sections.append(section)\n",
    "    \n",
    "    return headers, sections\n",
    "\n",
    "\n",
    "def clean_header(header):\n",
    "    # delete : (colon)\n",
    "    header = re.sub(r',', '', header)\n",
    "    new_header = re.sub(r':', '', header)\n",
    "    new_header = new_header.strip()\n",
    "    return new_header\n",
    "\n",
    "\n",
    "def clean_section(section):\n",
    "    # Replace multiple spaces with a space.\n",
    "    new_section = ' '.join(section.split())\n",
    "    return new_section\n",
    "\n",
    "\n",
    "def preprocess_discharge_summary(text):\n",
    "    text = clean_text(text)\n",
    "    headers, sections = split_section(text)\n",
    "    \n",
    "    # for duplicated keys problem when formulate dict type data\n",
    "#     for idx in range(len(headers)):\n",
    "#         h = clean_header(headers[idx])\n",
    "#         s = clean_section(sections[idx])\n",
    "#         result[h] = s\n",
    "    \n",
    "    new_headers, new_sections = [], []\n",
    "    for idx in range(len(headers)):\n",
    "        h = clean_header(headers[idx])\n",
    "        s = clean_section(sections[idx])\n",
    "        new_headers.append(h)\n",
    "        new_sections.append(s)\n",
    "    return [new_headers, new_sections]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    data = load_noteevents(file_path=LOAD_FILE_PATH)\n",
    "    print('Load NOTEEVENTS successfully!')\n",
    "    data       = get_discharge_summary(data)\n",
    "    print('Get discharge summary successfully!')\n",
    "    notes      = data.TEXT.apply(lambda x: json.dumps(preprocess_discharge_summary(x)))\n",
    "    print('Preprocess notes successfully!')\n",
    "    new_data   = pd.concat([data.ROW_ID, notes], axis=1)\n",
    "\n",
    "    save_csv_file(csv_data=new_data, file_path=SAVE_FILE_PATH)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract px section from notes successfully!\n",
      "save successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json \n",
    "import os\n",
    "import argparse\n",
    "\n",
    "ROOT_PATH = 'result'\n",
    "LOAD_FILE_PATH = os.path.join(ROOT_PATH,'sections.csv')\n",
    "SAVE_FILE_PATH = os.path.join(ROOT_PATH,'p_sections.csv')\n",
    "\n",
    "\n",
    "'''\n",
    "preprocessing for mimic discharge summary note\n",
    "\n",
    "1. load NOTEEVENTS.csv\n",
    "\n",
    "2. get discharge sumamry notes\n",
    "    a) NOTEVENTS.CATEGORY = 'Discharge Summary'\n",
    "    b) NOTEVENTS.DESCRIPTION = 'Report'\n",
    "    c) eliminate a short-note\n",
    "\n",
    "3. preprocess discharge sumamry notes\n",
    "    a) clean text\n",
    "    b) split sections by headers\n",
    "    \n",
    "4. save csv file\n",
    "    a) PK: NOTEVENTS.ROW_ID\n",
    "    b) TEXT: string(doubled-list)\n",
    "    \n",
    "'''\n",
    "\n",
    "def load_csv_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_csv_file(csv_data, file_path):\n",
    "    csv_data.to_csv(file_path, index=False)\n",
    "    return print('save successfully!')\n",
    "\n",
    "\n",
    "def extract_px_section(text):\n",
    "    px_section = []\n",
    "    text = json.loads(text) # change string format to dict\n",
    "    headers, sections = text[0], text[1]\n",
    "    \n",
    "    pos1, pos2, pos3, pos4 = -999, -999, -999, -999\n",
    "    \n",
    "    h1 = 'discharge medications'\n",
    "    h2 = 'discharge disposition'\n",
    "    h3 = 'discharge diagnosis'\n",
    "    h4 = 'discharge condition'\n",
    "    \n",
    "    if h1 in headers:\n",
    "        pos1 = headers.index(h1)\n",
    "    if h2 in headers:\n",
    "        pos2 = headers.index(h2)\n",
    "    if h3 in headers:\n",
    "        pos3 = headers.index(h3)\n",
    "    if h4 in headers:\n",
    "        pos4 = headers.index(h4)\n",
    "\n",
    "    if pos1 + pos2 + pos3 + pos4 > 0: # have all together\n",
    "        if pos1 < pos2 < pos3 < pos4: # well organized\n",
    "#             px_headers = headers[pos1:pos2]\n",
    "            px_section = ' '.join(sections[pos1:pos2])\n",
    "            \n",
    "    return px_section\n",
    "\n",
    "def extract_prx_section(text):\n",
    "    prx_section = []\n",
    "    text = json.loads(text) # change string format to dict\n",
    "    headers, sections = text[0], text[1]\n",
    "    \n",
    "    query = 'major surgical or invasive procedure'\n",
    "    try:\n",
    "        pos = headers.index(query)\n",
    "    except:\n",
    "        pos = \"\"\n",
    "        \n",
    "    if pos:\n",
    "        prx_section = sections[pos]\n",
    "            \n",
    "    return prx_section\n",
    "\n",
    "\n",
    "def main():\n",
    "    data       = load_csv_file(file_path=LOAD_FILE_PATH)\n",
    "    notes      = data.TEXT.apply(lambda x: json.dumps(extract_prx_section(x)))\n",
    "    print('extract px section from notes successfully!')\n",
    "    new_data   = pd.concat([data.ROW_ID, notes], axis=1)\n",
    "    \n",
    "    save_csv_file(csv_data=new_data, file_path=SAVE_FILE_PATH)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess successfully!\n",
      "data len: {} 26192\n",
      "save successfully!\n",
      "data1 len: {} 26192\n",
      "save successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, json\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import spacy, scispacy\n",
    "\n",
    "NOTE_PAHT = os.path.join('mimic_table','NOTEEVENTS.csv')\n",
    "LOAD_FILE_PATH = os.path.join(ROOT_PATH,'p_sections.csv')\n",
    "SEC_SAVE_FILE_PATH = os.path.join(ROOT_PATH,'p_sections.txt')\n",
    "ADM_SAVE_FILE_PATH = os.path.join(ROOT_PATH,'p_hadm_ids.txt')\n",
    "\n",
    "def load_csv_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_txt_file(txt_file, file_path):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        for txt in txt_file:\n",
    "            file.write(txt + '\\n')\n",
    "            file.write('\\n')\n",
    "    return print('save successfully!')\n",
    "\n",
    "\n",
    "def preprocess_scispacy(nlp, section_text):\n",
    "    section_text_p = ' '.join([token.text for token in nlp(section_text)])\n",
    "    return section_text_p\n",
    "\n",
    "\n",
    "def main():\n",
    "    data       = load_csv_file(file_path=LOAD_FILE_PATH)\n",
    "    # data = data.iloc[:10]\n",
    "    \n",
    "    # not na \n",
    "    data = data[data.TEXT.notna()]\n",
    "\n",
    "    # length > 200\n",
    "    data = data[data.TEXT.apply(lambda x: len(x) > 10)]\n",
    "\n",
    "    # delete \"\"\n",
    "    data1 = data.copy()\n",
    "    data1.TEXT = data.TEXT.apply(lambda x: x[1:-1])\n",
    "\n",
    "    # preprocessed by scispacy\n",
    "    nlp = spacy.load(\"en_core_sci_sm\")\n",
    "    data.TEXT = data1.TEXT.apply(lambda x: preprocess_scispacy(nlp, x))\n",
    "    del data1\n",
    "    print('preprocess successfully!')\n",
    "    \n",
    "\n",
    "    # recover and extract full info of data(subject_id, hamd_id)\n",
    "    noteevents = load_csv_file(file_path=NOTE_PAHT)\n",
    "    noteevents = noteevents[['ROW_ID', 'SUBJECT_ID', 'HADM_ID']]\n",
    "\n",
    "    # data=p / noteevents\n",
    "    data1 = noteevents[noteevents.ROW_ID.isin(data.ROW_ID)]\n",
    "    \n",
    "    # save txt file\n",
    "    print('data len: {}', len(data))\n",
    "    save_txt_file(txt_file=data.TEXT, file_path=SEC_SAVE_FILE_PATH)\n",
    "    hadm_id = data1.HADM_ID.astype(int).astype(str)\n",
    "    print('data1 len: {}', len(hadm_id))\n",
    "    save_txt_file(txt_file=hadm_id, file_path=ADM_SAVE_FILE_PATH)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy,scispacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_sm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_exp)",
   "language": "python",
   "name": "conda_exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
